{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Tester Analysis\n",
    "*Follow these steps to compare legacy results to the new api results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: SECRET_KEY being set as a one-shot\n",
      "Unable to configure logging, attempted conf:/home/notebook/.local/lib/python3.10/site-packages/ppr_api/logging.conf\n"
     ]
    }
   ],
   "source": [
    "%run ./local/setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find search batches (choose the data set)\n",
    "*find the ones you want to analyze*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674 2022-01-16 21:07:20.804192 SS 0.6 0.4 0.29\n"
     ]
    }
   ],
   "source": [
    "search_type = None\n",
    "after_date = None\n",
    "before_date = None\n",
    "### OPTIONAL: refine your batch search with any of the following\n",
    "# search_type = SearchRequest.SearchTypes.XXXX\n",
    "# before_date = _datetime_in_utc_\n",
    "after_date = \"2022-01-16 20:20:21.936128\"\n",
    "batches = TestSearchBatch.find_search_batches(search_type, after_date, before_date)\n",
    "for batch in batches:\n",
    "    print(batch.id, batch.test_date, batch.search_type, batch.sim_val_business, batch.sim_val_first_name, batch.sim_val_last_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ids of the batches you want to analyze\n",
    "batch_ids = []\n",
    "for batch in batches:\n",
    "    # fill in the clause (if you want all of them then set to True or remove)\n",
    "    if True:  # i.e. batch.id > _ , batch.sim_val_business > _ ...\n",
    "        batch_ids.append(batch.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the batch json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_to_analyze = []\n",
    "for batch_id in batch_ids:\n",
    "    batches_to_analyze.append(TestSearchBatch.find_by_id(batch_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass rate:  1.0\n",
      "number of failed searches:  0\n"
     ]
    }
   ],
   "source": [
    "searches_total = 0\n",
    "searches_passed = 0\n",
    "failed_searches = []\n",
    "all_searches = []\n",
    "for batch in batches_to_analyze:\n",
    "    for search in batch.searches:\n",
    "        searches_total += 1\n",
    "        all_searches.append(search)\n",
    "        if len(search.missed_matches(TestSearchResult.MatchType.EXACT.value)) > 0:\n",
    "            failed_searches.append(search)\n",
    "        else:\n",
    "            searches_passed += 1\n",
    "print('pass rate: ', searches_passed/searches_total)\n",
    "print('number of failed searches: ', len(failed_searches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failed Searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*select failed searches to analyze*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search in failed_searches:\n",
    "    json = search.json\n",
    "    print('###########################################################')\n",
    "    print('criteria: ', json['criteria'])\n",
    "    print('total expected: ', len(json['matchesExact']['resultsLegacy']), 'missed: ', len(json['matchesExact']['missedMatches']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print out json for specific search\n",
    "# print(failed_searches[0].json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_searches_analysis = []\n",
    "for search in failed_searches:\n",
    "    # fill in the clause (if you want all of them then set to True or remove)\n",
    "    if _clause_:  # i.e. search.search_criteria == _, len(search.missed_matches(TestSearchResult.MatchType.EXACT.value)) > _\n",
    "        exact_searches_analysis.append(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*missed matches*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "### manually iterate through exact_searches_analysis one by one to see the missed matches\n",
    "search = exact_searches_analysis[0]\n",
    "for match in search.missed_matches(TestSearchResult.MatchType.EXACT.value):\n",
    "    match['details'] = re.sub(' +', ' ', match['details'])\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "    print('result:', match['details'])\n",
    "    print('reg num:', match['documentId'])\n",
    "    print('index: ', match['index'])\n",
    "### print out all of them\n",
    "# for search in exact_searches_analysis:\n",
    "#     print('##################################################################################')\n",
    "#     print('criteria: ', search.search_criteria)\n",
    "#     print('Missed Matches')\n",
    "#     for match in search.missed_matches(TestSearchResult.MatchType.EXACT.value):\n",
    "#         print('-------------------------------------------------------------------------------')\n",
    "#         print('result:', match['details'])\n",
    "#         print('reg num:', match['documentId'])\n",
    "#         print('index: ', match['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*results diff*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criteria:  2M9PL3035JP016356                                                     \n",
      "-------------------------------------------------------------\n",
      "  legacy                           api\n",
      "-------------------------------------------------------------\n",
      "0: 563984M TR 2M9PL3035JP016356 2018 ARCTIC LT24TR  | 636985M {'type': 'TR', 'serialNumber': '2M9PL3035JP016356', 'year': 2018, 'make': 'ARCTIC LT24TR LOG TRAILER'}\n",
      "1:                    | 563984M {'type': 'TR', 'serialNumber': '2M9PL3035JP016356', 'year': 2018, 'make': 'ARCTIC LT24TR'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "### manually iterate through exact_searches_analysis one by one\n",
    "search = all_searches[0]\n",
    "print('criteria: ', search.search_criteria)\n",
    "print('-------------------------------------------------------------')\n",
    "print('  legacy                           api')\n",
    "print('-------------------------------------------------------------')\n",
    "legacy_results = search.get_results(TestSearchResult.MatchType.EXACT.value, TestSearchResult.Source.LEGACY.value)\n",
    "api_results = search.get_results(TestSearchResult.MatchType.EXACT.value, TestSearchResult.Source.API.value)\n",
    "length = max(len(legacy_results), len(api_results))\n",
    "for i in range(length):\n",
    "    if i < len(legacy_results) and i < len(api_results):\n",
    "        legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "        print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n",
    "    elif i < len(legacy_results):\n",
    "        legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "        print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} |')\n",
    "    elif i < len(api_results):\n",
    "        print(f'{i}:                    | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n",
    "\n",
    "### print out all of them\n",
    "# for search in exact_searches_analysis:\n",
    "#     print('criteria: ', search.search_criteria)\n",
    "#     print('-------------------------------------------------------------')\n",
    "#     print('  legacy                           api')\n",
    "#     print('-------------------------------------------------------------')\n",
    "#     legacy_results = search.get_results(TestSearchResult.MatchType.EXACT.value, TestSearchResult.Source.LEGACY.value)\n",
    "#     api_results = search.get_results(TestSearchResult.MatchType.EXACT.value, TestSearchResult.Source.API.value)\n",
    "#     length = max(len(legacy_results), len(api_results))\n",
    "#     for i in range(length):\n",
    "#         if i < len(legacy_results) and i < len(api_results):\n",
    "#             legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "#             print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n",
    "#         elif i < len(legacy_results):\n",
    "#             legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "#             print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} |')\n",
    "#         elif i < len(api_results):\n",
    "#             print(f'{i}:                    | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass rate:  0.0\n",
      "number of failed searches:  1\n"
     ]
    }
   ],
   "source": [
    "searches_total = 0\n",
    "searches_passed = 0\n",
    "failed_searches = []\n",
    "for batch in batches_to_analyze:\n",
    "    for search in batch.searches:\n",
    "        searches_total += 1\n",
    "        # fails if missed matches\n",
    "        if len(search.missed_matches(TestSearchResult.MatchType.SIMILAR.value)) > 0:\n",
    "            failed_searches.append(search)\n",
    "        # fails if order is off\n",
    "        elif search.avg_index_diff(TestSearchResult.MatchType.SIMILAR.value) != 0:\n",
    "            failed_searches.append(search)\n",
    "        else:\n",
    "            searches_passed += 1\n",
    "print('pass rate: ', searches_passed/searches_total)\n",
    "print('number of failed searches: ', len(failed_searches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failed searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*select failed searches to analyze*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################################\n",
      "criteria:  2M9PL3035JP016356                                                     \n",
      "total expected:  3  missed:  0\n",
      "first fail index:  0\n",
      "avg index diff:  1.0\n"
     ]
    }
   ],
   "source": [
    "for search in failed_searches:\n",
    "    json = search.json\n",
    "    print('###########################################################')\n",
    "    print('criteria: ', json['criteria'])\n",
    "    print('total expected: ', len(json['matchesSimilar']['resultsLegacy']), ' missed: ', len(json['matchesSimilar']['missedMatches']))\n",
    "    print('first fail index: ', json['matchesSimilar']['firstFailIndex'])\n",
    "    print('avg index diff: ', json['matchesSimilar']['avgIndexDiff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print out json for specific search\n",
    "# print(failed_searches[0].json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_searches_analysis = []\n",
    "for search in failed_searches:\n",
    "    # fill in the clause (if you want all of them then set to True or remove)\n",
    "    if True:  # i.e. search.search_criteria == _, len(search.missed_matches(TestSearchResult.MatchType.SIMILAR.value)) > _\n",
    "        similar_searches_analysis.append(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*first failed indexes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "### manually iterate through\n",
    "search = similar_searches_analysis[0]\n",
    "print(search.fail_index(TestSearchResult.MatchType.SIMILAR.value))\n",
    "\n",
    "### print out all of them\n",
    "# for search in similar_searches_analysis:\n",
    "#     print(search.fail_index(TestSearchResult.MatchType.SIMILAR.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of searches with fail indexes:  1\n",
      "avg fail index:  0.0\n"
     ]
    }
   ],
   "source": [
    "### avgs\n",
    "total_no_fails = 0\n",
    "total_fail_index = 0\n",
    "for search in similar_searches_analysis:\n",
    "    fail_index = search.fail_index(TestSearchResult.MatchType.SIMILAR.value)\n",
    "    if fail_index == -1:\n",
    "        total_no_fails += 1\n",
    "    else:\n",
    "        total_fail_index += fail_index\n",
    "\n",
    "num_searches_failed = len(similar_searches_analysis) - total_no_fails\n",
    "print('Number of searches with fail indexes: ', num_searches_failed)\n",
    "print('avg fail index: ', total_fail_index/num_searches_failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*avg order difference between legacy and api results (does NOT include missed matches)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "### manually iterate through\n",
    "search = similar_searches_analysis[0]\n",
    "print(search.avg_index_diff(TestSearchResult.MatchType.SIMILAR.value))\n",
    "\n",
    "### print out all of them\n",
    "# for search in similar_searches_analysis:\n",
    "#     print(search.avg_index_diff(TestSearchResult.MatchType.SIMILAR.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*missed matches*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criteria:  2M9PL3035JP016356                                                     \n",
      "Missed Matches\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "### manually iterate through\n",
    "search = similar_searches_analysis[0]\n",
    "print('criteria: ', search.search_criteria)\n",
    "print('Missed Matches')\n",
    "for match in search.missed_matches(TestSearchResult.MatchType.SIMILAR.value):\n",
    "    match['details'] = re.sub(' +', ' ', match['details'])\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "    print('result:', match['details'])\n",
    "    print('reg num:', match['documentId'])\n",
    "    print('index: ', match['index'])\n",
    "\n",
    "### print out all of them\n",
    "# for search in similar_searches_analysis:\n",
    "#     print('##################################################################################')\n",
    "#     print('criteria: ', search.search_criteria)\n",
    "#     print('Missed Matches')\n",
    "#     for match in search.missed_matches(TestSearchResult.MatchType.SIMILAR.value):\n",
    "#         print('-------------------------------------------------------------------------------')\n",
    "#         print('result:', match['details'])\n",
    "#         print('reg num:', match['documentId'])\n",
    "#         print('index: ', match['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*results diff*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criteria:  2M9PL3035JP016356                                                     \n",
      "-------------------------------------------------------------\n",
      "  legacy                           api\n",
      "-------------------------------------------------------------\n",
      "0: 978910L MV 2T9YAAZC1LD016356 2020 TYCROP 53' SMOOTHFLOW  | 5931105 {'type': 'TR', 'serialNumber': '2DELGFA2141016356', 'year': 2004, 'make': 'DOEPKER', 'model': 'SUPER B'}\n",
      "1: 210153M TR 2T9YAATC9DD016356 2013 TYCROP BIG BOX END DUMP L  | 210153M {'type': 'TR', 'serialNumber': '2T9YAATC9DD016356', 'year': 2013, 'make': 'TYCROP', 'model': 'BIG BOX END DUMP L'}\n",
      "2: 232649H TR 2T9YAATC9DD016356 2013 TYCROP LEAD  | 232649H {'type': 'TR', 'serialNumber': '2T9YAATC9DD016356', 'year': 2013, 'make': 'TYCROP', 'model': 'LEAD'}\n",
      "3:                    | 978910L {'type': 'MV', 'serialNumber': '2T9YAAZC1LD016356', 'year': 2020, 'make': 'TYCROP', 'model': \"53' SMOOTHFLOW\"}\n",
      "4:                    | 692918M {'type': 'TR', 'serialNumber': '527SR5320KM016356', 'year': 2019, 'make': 'CIMC', 'model': 'REEFER TRAILER REEFE'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "### manually iterate through similar_searches_analysis one by one\n",
    "search = similar_searches_analysis[0]\n",
    "print('criteria: ', search.search_criteria)\n",
    "print('-------------------------------------------------------------')\n",
    "print('  legacy                           api')\n",
    "print('-------------------------------------------------------------')\n",
    "legacy_results = search.get_results(TestSearchResult.MatchType.SIMILAR.value, TestSearchResult.Source.LEGACY.value)\n",
    "api_results = search.get_results(TestSearchResult.MatchType.SIMILAR.value, TestSearchResult.Source.API.value)\n",
    "length = max(len(legacy_results), len(api_results))\n",
    "for i in range(length):\n",
    "    if i < len(legacy_results) and i < len(api_results):\n",
    "        legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "        print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n",
    "    elif i < len(legacy_results):\n",
    "        legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "        print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} |')\n",
    "    elif i < len(api_results):\n",
    "        print(f'{i}:                    | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n",
    "\n",
    "### print out all of them\n",
    "# for search in similar_searches_analysis:\n",
    "#     print('criteria: ', search.search_criteria)\n",
    "#     print('-------------------------------------------------------------')\n",
    "#     print('  legacy                           api')\n",
    "#     print('-------------------------------------------------------------')\n",
    "#     legacy_results = search.get_results(TestSearchResult.MatchType.SIMILAR.value, TestSearchResult.Source.LEGACY.value)\n",
    "#     api_results = search.get_results(TestSearchResult.MatchType.SIMILAR.value, TestSearchResult.Source.API.value)\n",
    "#     length = max(len(legacy_results), len(api_results))\n",
    "#     for i in range(length):\n",
    "#         if i < len(legacy_results) and i < len(api_results):\n",
    "#             legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "#             print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')\n",
    "#         elif i < len(legacy_results):\n",
    "#             legacy_results[i]['details'] = re.sub(' +', ' ', legacy_results[i]['details'])\n",
    "#             print(f'{i}: {legacy_results[i][\"documentId\"]} {legacy_results[i][\"details\"]} |')\n",
    "#         elif i < len(api_results):\n",
    "#             print(f'{i}:                    | {api_results[i][\"documentId\"]} {api_results[i][\"details\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MD file of notebook run\n",
    "**NOTE:** save notebook (i.e. _cmd s_) now to have results show in markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_name = nb_name[:-6]+'.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: jupyter: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'jupyter nbconvert $1 --to markdown --output $2\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-s \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$nb_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$md_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjupyter nbconvert $1 --to markdown --output $2\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2257\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2255\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2256\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2257\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'jupyter nbconvert $1 --to markdown --output $2\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash -s \"$nb_name\" \"$md_name\"\n",
    "jupyter nbconvert $1 --to markdown --output $2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
